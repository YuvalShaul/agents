{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54c86fc1",
   "metadata": {},
   "source": [
    "### Storing chunks into a vector database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ab96e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import json\n",
    "import os\n",
    "\n",
    "# 1. Initialize the Persistent Client\n",
    "# This saves the database to a folder on your laptop so it persists after you close the script.\n",
    "# You will find there sqlite file for metadata and HNSW file(s) for the vectors)\n",
    "client = chromadb.PersistentClient(path=\"./medcare_vector_db\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "591dfc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yuval\\Documents\\courses\\AI\\agents\\5-embeddings\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 1174.34it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 2. Define the Embedding Function Explicitly\n",
    "# We use 'all-MiniLM-L6-v2' which is fast, lightweight, and runs locally.\n",
    "# If you want a medical-specific model later, you just change the 'model_name'.\n",
    "# This will download the model to something like:\n",
    "#    ~/.cache/torch/sentence_transformers/\n",
    "emb_fn = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "980a4f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create (or get) the Collection\n",
    "# In the context of vector databases like ChromaDB, a Collection is the equivalent of a Table \n",
    "# in a traditional relational database (like SQL).\n",
    "# Organization: \n",
    "#   It is a way to group related documents and their corresponding vector embeddings together. \n",
    "#   For example, you might have one collection called \"medcare_internal_docs\" \n",
    "#   for employee policies and another completely separate collection called \"patient_records\" for medical data.\n",
    "#\n",
    "# Here, we pass the embedding function so Chroma knows exactly how to process text.\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"medcare_internal_docs\", \n",
    "    embedding_function=emb_fn    # Used for inserting into the DB and also for searching\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1b9ec8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 100 chunks so far...\n",
      "Inserted 200 chunks so far...\n",
      "Inserted 300 chunks so far...\n",
      "Inserted 400 chunks so far...\n",
      "Inserted 500 chunks so far...\n",
      "\n",
      "✅ Success! Loaded a total of 523 Medcare chunks into the vector database.\n"
     ]
    }
   ],
   "source": [
    "# 4. Load your JSONL file and insert in batches\n",
    "jsonl_file_path = \"medcare_knowledge_base.jsonl\" # <--- Update this to your filename\n",
    "\n",
    "batch_size = 100\n",
    "documents = []\n",
    "metadatas = []\n",
    "ids = []\n",
    "total_inserted = 0\n",
    "\n",
    "with open(jsonl_file_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        chunk_data = json.loads(line)\n",
    "        \n",
    "        text_content = chunk_data.get(\"text\", \"\")\n",
    "        metadata_part = chunk_data.get(\"metadata\", {})\n",
    "        source_info = metadata_part.get(\"source_file\", \"unknown_document\")\n",
    "        \n",
    "        if text_content:\n",
    "            documents.append(text_content)\n",
    "            metadatas.append({\"source\": source_info, \"chunk_index\": i})\n",
    "            ids.append(f\"medcare_{i}\")\n",
    "            \n",
    "        # Insert in batches to prevent memory issues\n",
    "        if len(documents) >= batch_size:\n",
    "            collection.add(documents=documents, metadatas=metadatas, ids=ids)\n",
    "            total_inserted += len(documents)\n",
    "            documents = []  # Reset batch\n",
    "            metadatas = []\n",
    "            ids = []\n",
    "            print(f\"Inserted {total_inserted} chunks so far...\")\n",
    "\n",
    "    # Insert any remaining documents after the loop finishes\n",
    "    if documents:\n",
    "        collection.add(documents=documents, metadatas=metadatas, ids=ids)\n",
    "        total_inserted += len(documents)\n",
    "\n",
    "print(f\"\\n✅ Success! Loaded a total of {total_inserted} Medcare chunks into the vector database.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
