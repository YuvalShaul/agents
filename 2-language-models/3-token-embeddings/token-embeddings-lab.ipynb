{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb5b055e",
   "metadata": {},
   "source": [
    "## Token Embeddings\n",
    "This lab uses the [gensim](https://github.com/piskvorky/gensim) library to demonstrate word/token embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75397922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21a2833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Download/Load a pre-trained model (GloVe trained on Wikipedia)\n",
    "#    GloVe - Global Vectors \n",
    "#    It was trained on the entirety of Wikipedia (2014) plus the Gigaword 5 news dataset.\n",
    "#    It is good for infering only - not for training\n",
    "#    Each vector is 100 values length (dimension)\n",
    "model = api.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58a0c076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('porcine', 0.5438385009765625), ('canine', 0.5419136881828308), ('yelping', 0.49510225653648376)]\n"
     ]
    }
   ],
   "source": [
    "# 2. Perform the arithmetic: (feline - tiger) + wolf\n",
    "# Take feline, remove tiger from it (thats the characteristic) then add wolf\n",
    "\n",
    "result = model.most_similar(positive=['feline', 'wolf'], negative=['tiger'], topn=3)\n",
    "\n",
    "print(result) \n",
    "# Output will likely be: [('man', 0.82...)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6462528d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bread', 0.5432527661323547), ('baked', 0.537010908126831), ('potatoes', 0.5341463685035706)]\n"
     ]
    }
   ],
   "source": [
    " # I want to do:   (Italy - pasta)  + Israel\n",
    "result = model.most_similar(positive=['pasta', 'israel'], negative=['italy'], topn=3)\n",
    "print(result) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4dd117fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('aunt', 0.8368030190467834), ('daughter', 0.8227197527885437), ('niece', 0.8220989108085632)]\n"
     ]
    }
   ],
   "source": [
    "# I want to do:   (Italy - pasta)  + Israel\n",
    "result = model.most_similar(positive=['woman', 'uncle'], negative=['man'], topn=3)\n",
    "print(result) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee385f9",
   "metadata": {},
   "source": [
    "Exercise\n",
    "- try to \"plqy\" with semantics of words, in a manner simmilar to the previous examples\n",
    "- Try to follow relations, like:\n",
    "  - plural/singular\n",
    "  - country/national currency\n",
    "  - preditor/prey\n",
    "  - source/material (e.g water is coming from a faucet, light is coming from a lamp)\n",
    "Why doesn't it work easily?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe86d1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
